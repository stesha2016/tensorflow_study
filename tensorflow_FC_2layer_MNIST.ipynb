{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('../data/MNIST_data', one_hot=False, source_url='http://yann.lecun.com/exdb/mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape (55000, 784)\n",
      "training label shape (55000,)\n"
     ]
    }
   ],
   "source": [
    "print('training data shape', mnist.train.images.shape)\n",
    "print('training label shape', mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "x_input = tf.placeholder(tf.float32, [None, 784])\n",
    "y_input = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "# FC1\n",
    "W_fc1 = weight_variable([784, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(x_input, W_fc1) + b_fc1)\n",
    "\n",
    "# FC2\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "logits = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499, train cost 0.136511, accuary 0.960000, test cost 0.122575, accuary 0.963200\n",
      "step 999, train cost 0.108682, accuary 0.980000, test cost 0.103412, accuary 0.968400\n",
      "step 1499, train cost 0.026517, accuary 1.000000, test cost 0.089856, accuary 0.971500\n",
      "step 1999, train cost 0.006726, accuary 1.000000, test cost 0.069395, accuary 0.979200\n",
      "step 2499, train cost 0.009217, accuary 1.000000, test cost 0.066975, accuary 0.980000\n",
      "step 2999, train cost 0.037392, accuary 0.980000, test cost 0.063149, accuary 0.981300\n",
      "step 3499, train cost 0.015646, accuary 0.990000, test cost 0.070212, accuary 0.980500\n",
      "step 3999, train cost 0.002749, accuary 1.000000, test cost 0.068196, accuary 0.980800\n",
      "step 4499, train cost 0.005980, accuary 1.000000, test cost 0.073282, accuary 0.980300\n",
      "step 4999, train cost 0.012331, accuary 1.000000, test cost 0.075655, accuary 0.980500\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y_input, logits = logits))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "cross_prediction = tf.equal(tf.argmax(logits, 1), y_input)\n",
    "accuracy = tf.reduce_mean(tf.cast(cross_prediction, tf.float32))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(5000):\n",
    "    x_batch, y_batch = mnist.train.next_batch(batch_size=100)\n",
    "    cost, acc, _ = sess.run([cross_entropy, accuracy, train_step], feed_dict={x_input: x_batch, y_input: y_batch})\n",
    "    if (i + 1) % 500 == 0:\n",
    "        test_cost, test_acc = sess.run([cross_entropy, accuracy], feed_dict={x_input: mnist.test.images, y_input: mnist.test.labels})\n",
    "        print('step {}, train cost {:.6f}, accuary {:.6f}, test cost {:.6f}, accuary {:.6f}'.format(i, cost, acc, test_cost, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
