{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 不打印 warning \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 设置GPU按需增长\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(data_path = '../data/sketchy_000000000000/'):\n",
    "    \"\"\"解析文件夹，获取每个文件的路径和标签。\"\"\"\n",
    "    img_paths = list()\n",
    "    labels = list()\n",
    "    class_dirs = sorted(os.listdir(data_path))\n",
    "    dict_class2id = dict()\n",
    "    for i in range(len(class_dirs)):\n",
    "        label = i\n",
    "        class_dir = class_dirs[i]\n",
    "        dict_class2id[class_dir] = label\n",
    "        class_path = os.path.join(data_path, class_dir)  # 每类的路径\n",
    "        file_names = sorted(os.listdir(class_path))\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(class_path, file_name)\n",
    "            img_paths.append(file_path)\n",
    "            labels.append(label)\n",
    "    return img_paths, labels\n",
    "\n",
    "img_paths, labels = get_file_path()\n",
    "print(len(img_paths))\n",
    "print(len(labels))\n",
    "img0 = img_paths[0]\n",
    "print(img0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_png(img_path, label, height=256, width=256, channel=3):\n",
    "    \"\"\"根据 img_path 读入图片并做相应处理\"\"\"\n",
    "    # 从硬盘上读取图片\n",
    "    img = tf.read_file(img_path)\n",
    "    img_decoded = tf.image.decode_png(img, channels=channel)\n",
    "    # resize\n",
    "    img_resized = tf.image.resize_images(img_decoded, [height, width])\n",
    "    # normalize \n",
    "    img_norm = img_resized * 1.0 / 127.5 - 1.0\n",
    "    return img_norm, label\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((img_paths, labels))\n",
    "dataset = dataset.map(parse_png)\n",
    "print('parsing image', dataset)\n",
    "dataset = dataset.shuffle(buffer_size=5000).repeat().batch(256)\n",
    "print('batch', dataset)\n",
    "\n",
    "# 生成迭代器\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "print(iterator)\n",
    "\n",
    "time0 = time.time()\n",
    "for count in range(1000):\n",
    "    X_batch, y_batch = sess.run(iterator.get_next())\n",
    "#     print('count = {} : X.shape = {}, y[:10] = {}, pass {}s'.format(count, X_batch.shape, y_batch[:10], time.time() - time0))\n",
    "#     time0 = time.time()\n",
    "print(time.time() - time0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use tf.data.Dataset to create dataset for image(png) data.\n",
    "With TF Queue, shuffle data\n",
    "\n",
    "refer: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/5_DataManagement/build_an_image_dataset.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')  # 不打印 warning\n",
    "import tensorflow as tf\n",
    "\n",
    "# 设置GPU按需增长\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "def get_file_path(data_path='../data/sketchy_000000000000/'):\n",
    "    \"\"\"解析文件夹，获取每个文件的路径和标签。\"\"\"\n",
    "    img_paths = list()\n",
    "    labels = list()\n",
    "    class_dirs = sorted(os.listdir(data_path))\n",
    "    dict_class2id = dict()\n",
    "    for i in range(len(class_dirs)):\n",
    "        label = i\n",
    "        class_dir = class_dirs[i]\n",
    "        dict_class2id[class_dir] = label\n",
    "        class_path = os.path.join(data_path, class_dir)  # 每类的路径\n",
    "        file_names = sorted(os.listdir(class_path))\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(class_path, file_name)\n",
    "            img_paths.append(file_path)\n",
    "            labels.append(label)\n",
    "    return img_paths, labels\n",
    "\n",
    "\n",
    "def get_batch(img_paths, labels, batch_size=128, height=256, width=256, channel=3):\n",
    "    \"\"\"根据 img_path 读入图片并做相应处理\"\"\"\n",
    "    # 从硬盘上读取图片\n",
    "    img_paths = np.asarray(img_paths)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    img_paths = tf.convert_to_tensor(img_paths, dtype=tf.string)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "    # Build a TF Queue, shuffle data\n",
    "    image, label = tf.train.slice_input_producer([img_paths, labels], shuffle=True)\n",
    "    # Read images from disk\n",
    "    image = tf.read_file(image)\n",
    "    image = tf.image.decode_jpeg(image, channels=channel)\n",
    "    # Resize images to a common size\n",
    "    image = tf.image.resize_images(image, [height, width])\n",
    "    # Normalize\n",
    "    image = image * 1.0 / 127.5 - 1.0\n",
    "    # Create batches\n",
    "    X_batch, y_batch = tf.train.batch([image, label], batch_size=batch_size,\n",
    "                                      capacity=batch_size * 8,\n",
    "                                      num_threads=4)\n",
    "    return X_batch, y_batch\n",
    "\n",
    "\n",
    "img_paths, labels = get_file_path()\n",
    "X_batch, y_batch = get_batch(img_paths, labels)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "time0 = time.time()\n",
    "for count in range(100):   # 11s for 100batch\n",
    "    _X_batch, _y_batch = sess.run([X_batch, y_batch])\n",
    "    sys.stdout.write(\"\\rloop {}, pass {:.2f}s\".format(count, time.time() - time0))\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_mode \tbuffer_size \t100 batch(s)\n",
    "one-shot \t2000 \t75\n",
    "one-shot \t5000 \t86\n",
    "tf.queue \t2000 \t11\n",
    "tf.queue \t5000 \t11\n",
    "tfrecord \t2000 \t5.3\n",
    "tfrecord \t5000 \t5.3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
